# SCT_ML_04
This project uses MediaPipe and OpenCV to detect and track hand gestures in video input. It processes each video frame in real-time and overlays hand landmarks, enabling gesture recognition. Built as part of my internship at SkillCraft Technology.
## 📌 Files Included
- Gesture_Recognition.ipynb: Main notebook containing the code.
- hand_tracking_output.mp4: Output video file with hand landmarks (not uploaded due to size, generated after running notebook).

- 📽 Watch the output video on LinkedIn:https://www.linkedin.com/posts/bhaskar-jha-665639327_skillcraft-machinelearning-opencv-activity-7340233572525514752-uetF?utm_source=share&utm_medium=member_android&rcm=ACoAAFJ_a20B3G92yjpXJNHnNbC9p1dJh_p7PSg

## 🧪 How It Works
1. Loads an input video file.
2. Uses MediaPipe to detect hand landmarks.
3. Draws the landmarks on each frame using OpenCV.
4. Saves the processed video.

## 🚀 Run this on Kaggle
To generate the output video, open this notebook in [Kaggle](https://www.kaggle.com/code):
1. Upload the notebook.
2. Upload your input .mp4 video file.
3. Run the cells to process and generate hand_tracking_output.mp4.

💡 *Tip:* Download the generated video from Kaggle's "Files" section (bottom left sidebar).

## ❗ Notes
- Video output not included due to GitHub size limitations.
- If running on Google Colab, zip and download steps may require additional handling.
